<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.1 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>(Res) Focal Gradient Loss: Are we looking at focal loss correctly? - Mikes ML blog</title>
<meta name="description" content="In this post I discuss a new loss function for single stage object detectors that like retinanets focal loss is adaptive, but works at the gradient level rather than at the objective function level">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Mikes ML blog">
<meta property="og:title" content="(Res) Focal Gradient Loss: Are we looking at focal loss correctly?">
<meta property="og:url" content="/FocalGradLoss/">


  <meta property="og:description" content="In this post I discuss a new loss function for single stage object detectors that like retinanets focal loss is adaptive, but works at the gradient level rather than at the objective function level">







  <meta property="article:published_time" content="2019-10-20T00:00:00-04:00">





  

  


<link rel="canonical" href="/FocalGradLoss/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Michael Shliselberg",
      "url": "/"
    
  }
</script>


  <meta name="google-site-verification" content="ssEy9GjG7EEGOSmwhT5SxFQpr4mSvw2LK-IrNVc-aYg" />





<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Mikes ML blog Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Mikes ML blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/" >About Me</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name"></h3>
    
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="(Res) Focal Gradient Loss: Are we looking at focal loss correctly?">
    <meta itemprop="description" content="In this post I discuss a new loss function for single stage object detectors that like retinanets focal loss is adaptive, but works at the gradient level rather than at the objective function level">
    <meta itemprop="datePublished" content="October 20, 2019">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">(Res) Focal Gradient Loss: Are we looking at focal loss correctly?
</h1>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Retinanet is a near state-of-the-art object detector that using a simple adaptive weighting scheme, helps bridge some of the gap between one and two stage object detectors by dealing with inherent class imbalance from the large background set constructed by the anchoring process. Specifically they use Focal Loss</p>

<script type="math/tex; mode=display">FL(p) \propto - (1-p)^\gamma log(p)</script>

<p>The usage of <script type="math/tex">(1-p)^\gamma</script> down weights the categorical cross entropy loss along with how high <script type="math/tex">p</script> is. This is parameterized by <script type="math/tex">\gamma</script>, where the higher it is, the greater the down weighting is. In their paper they make it clear this choice of adaptive weighting is arbitrary and could be replaced with other schemes.</p>

<p>The question I pose with this, is does this accomplish their goal? (I asked this a while back in a <a href="https://ai.stackexchange.com/questions/13755/does-retina-nets-focal-loss-accomplish-its-goal">stack exchange question</a>). Given the lack of response in that post, I decided to investigate this myself. I propose another simple adaptive weighting scheme, but I propose applying the approach onto the gradient directly. I do this because most optimizers use a form of gradient descent <script type="math/tex">\theta \leftarrow \theta - \nabla_{\theta}L</script>, and so masking the gradient, directly masks how much is learned by each element. I call this set of losses, <em>focal gradient loss</em></p>

<script type="math/tex; mode=display">FGL(p) \propto - StopGradient((1-p)^\gamma) \ log(p)</script>

<h3 id="comparing-the-objective-functions">Comparing the objective functions</h3>
<p>Its hard to understand it comparitively with the <script type="math/tex">StopGradient</script> function, so first lets look at their gradients</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
    \dot{FL(p)} &= - \frac{(1-p)^\gamma }{p} + \gamma (1-p)^{\gamma - 1} \ log(p)\\
    &= -(1-p)^\gamma \ \dot{CE(p)} + \gamma (1-p)^{\gamma - 1} \ log(p)\\
    &= -(1-p)^\gamma \ \dot{CE(p)} + R(p) \\
    \dot{FGL(p)} &= - \frac{(1-p)^\gamma }{p} \\
    &= -(1-p)^\gamma \ \dot{CE(p)}  \
\end{aligned} %]]></script>

<p>Looking at these, we see the focal-loss is a masked version of adaptive weighting plus a residual, <script type="math/tex">R(p)</script>. This is the differentiating factor in the two appraoches. We can rewrite the residual as <script type="math/tex">R(p) = -\gamma * FL_{\gamma -1}(p)</script>. It is difficult to say what this does in the optimization perspective, but in terms of sheer magnitude it will always increase the gradient (because the gradient is always negative), moreso if a loss variant is high. This is difficult to describe intuitively but it may be be seen as an additive adaptive bias. This actually increases the spread if you do the math out which may be seen as a benefit but difficult to say for certain, which is why I perform this experiment.</p>

<p align="center">
  <img src="/images/FocalGradientLoss/focal_gradients.png" />
</p>

<p>Even though stop_gradient makes it not easily comparable in the loss space, we can integrate its gradient to see its effective equivalent. For values of <script type="math/tex">\gamma</script> that arent integers, the integral becomes alot more complicated, so for ease lets just look at the integer case</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
    L(p) &= \int_{z=1}^p -\frac{(1-z)^\gamma}{z} dz\\
    &= -log(p) - \sum_{i=1}^\gamma {\gamma \choose i}\frac{(-p)^i - (-1)^i}{i} \
\end{aligned} %]]></script>

<p>Note that the bottom bound of the integral is arbitrary, because it only effects the constant, but since we set <script type="math/tex">FGL(1)=0</script> from the stop_gradient formulation, I use <script type="math/tex">z=1</script> to keep it consistent. Now plotting these we see the following</p>

<p align="center">
  <img src="/images/FocalGradientLoss/focal_objectives.png" />
</p>

<p>As you can see, focal gradient loss is always lower than the respective focal loss which is understandable based on the spread differential caused by the Residual.</p>

<h3 id="experiment">Experiment</h3>
<p>Due to computational reasons, we will test on only the setting of <script type="math/tex">\gamma = 2</script> for 15 epochs on PASCAL VOC 2012. We use the keras-retinanet open source package to do this. Only adjustments I add to the repo is make the custom loss function, and I adjust the training to work with Horovod for more efficient parallelization (I will take any speedups I can get :D)</p>

<p align="center">
  <img src="/images/FocalGradientLoss/fl_vs_fgl.png" />
</p>

<p>Looking at the results we see they perform similarly. Focal Gradient Loss actually does have a slightly better mAP, but this could be due to noise produced in the training procedure. There is also more noise in general in the Focal Gradient Loss’s training compared to Focal Losses– this may be due to the lack of that additive bias. From this singular (and incomplete) experiment there isnt enough to make conclusions, but if I were forced to do so, I would say the perform similarly but Focal Gradient seems less robust. <br />
I will hopefully be adding more experiments in the future. Stay tuned.</p>


        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#object-detection" class="page__taxonomy-item" rel="tag">object detection</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#optimization" class="page__taxonomy-item" rel="tag">optimization</a><span class="sep">, </span>
    
      
      
      <a href="/tags/#research" class="page__taxonomy-item" rel="tag">research</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2019-10-20T00:00:00-04:00">October 20, 2019</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%28Res%29+Focal+Gradient+Loss%3A+Are+we+looking+at+focal+loss+correctly%3F%20%2FFocalGradLoss%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=%2FFocalGradLoss%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=%2FFocalGradLoss%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ILSampling/" class="pagination--pager" title="(Res) Intermediate Loss Sampling, a Differentiable Categorical Sampler
">Previous</a>
    
    
      <a href="/HackUmassMentor/" class="pagination--pager" title="(Pers) Hack Umass Mentor
">Next</a>
    
  </nav>

    </div>

    
      <div class="page__comments">
  
  
      <h4 class="page__comments-title">Leave a comment</h4>
      <section class="fb-comments" data-href="/FocalGradLoss/" data-mobile="true" data-num-posts="5" data-width="100%" data-colorscheme="dark"></section>
    
</div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/SuperMasks/" rel="permalink">(Res) Super-Masks: Are They Good Initializations?
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">In this post I discuss a Super Masks and their potential as initializations, similar to the lottery ticket hypothesis
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/HackUmassMentor/" rel="permalink">(Pers) Hack Umass Mentor
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">This past weekend I had the pleasure of being a mentor at Hack Umass. In this post I discuss how the experience was along with common debugging ideas that ar...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/ILSampling/" rel="permalink">(Res) Intermediate Loss Sampling, a Differentiable Categorical Sampler
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">I propose a novel sampling approach, leveraging an intermediate loss function to differentiate through a categorical draw. I compare this method to the commo...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/ANNagram/" rel="permalink">(Rand) ANNagram
</a>
      
    </h2>
    
    <p class="archive__item-excerpt" itemprop="description">ANNagram is a neural network to take a set of letters and output a possible word. I use a pointer network with a transformer backbone for this task. In the p...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
          <li><a href="https://github.com/mshlis" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> gitHub</a></li>
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Michael Shliselberg. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script src="https://kit.fontawesome.com/4eee35f757.js"></script>







  <script>
  window.ga=function(){ga.q.push(arguments)};ga.q=[];ga.l=+new Date;
  ga('create','UA-151394608-1','auto');
  ga('set', 'anonymizeIp', false);
  ga('send','pageview')
</script>
<script src="https://www.google-analytics.com/analytics.js" async></script>






    <div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.5";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>
  





<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


  </body>
</html>
